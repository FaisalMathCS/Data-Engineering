{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af0245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b385d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, decode \n",
    "import json\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f22bea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STarting a spark Session\n",
      "Session Established!\n"
     ]
    }
   ],
   "source": [
    "print(\"STarting a spark Session\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ConsumeKafka\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.0\") \\\n",
    "    .getOrCreate()\n",
    "print(\"Session Established!\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a4ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark \\\n",
    "    .read \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"input\") \\\n",
    "    .load()\n",
    "#df will be retrned as binary so needs parsing \n",
    "df = df_raw.select(decode(col(\"value\"), \"UTF-8\").alias(\"value_string\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4545e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df will be in json format so convert to df using the structure of the file \n",
    "def parse_and_cast(json_str):\n",
    "    # Parse the JSON string\n",
    "    data = json.loads(json_str)\n",
    "\n",
    "    # Manually cast the fields\n",
    "    return Row(\n",
    "        _c0=str(data[\"_c0\"]),\n",
    "        UTC=str(data[\"UTC\"]),\n",
    "        Temperature_C=float(data[\"Temperature[C]\"]),\n",
    "        Humidity_Percent=float(data[\"Humidity[%]\"]),\n",
    "        TVOC_ppb=int(data[\"TVOC[ppb]\"]),\n",
    "        eCO2_ppm=int(data[\"eCO2[ppm]\"]),\n",
    "        Raw_H2=int(data[\"Raw H2\"]),\n",
    "        Raw_Ethanol=int(data[\"Raw Ethanol\"]),\n",
    "        Pressure_hPa=float(data[\"Pressure[hPa]\"]),\n",
    "        PM1=float(data[\"PM1\"]),\n",
    "        PM2_5=float(data[\"PM2_5\"]),\n",
    "        NC0_5=int(data[\"NC0_5\"]),\n",
    "        NC1_5=float(data[\"NC1_5\"]),\n",
    "        NC2_5=float(data[\"NC2_5\"]),\n",
    "        CNT=int(data[\"CNT\"]),\n",
    "        Fire_Alarm=str(data[\"Fire Alarm\"])\n",
    "    )\n",
    "\n",
    "# Apply the function to each row\n",
    "# rdd = df.rdd.map(lambda row: parse_and_cast(row.value_string))\n",
    "\n",
    "# Convert the RDD back to a DataFrame\n",
    "# new_df = spark.createDataFrame(rdd)\n",
    "\n",
    "# Show the result\n",
    "# new_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6141cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df.rdd.map(lambda row: parse_and_cast(row.value_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4d9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de4d8e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+\n",
      "|_c0|UTC       |Temperature_C|Humidity_Percent|TVOC_ppb|eCO2_ppm|Raw_H2|Raw_Ethanol|Pressure_hPa|PM1 |PM2_5|NC0_5|NC1_5|NC2_5|CNT|Fire_Alarm|\n",
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+\n",
      "|0  |1654733331|20.0         |57.36           |0       |400     |12306 |18520      |939.735     |0.0 |0.0  |0    |0.0  |0.0  |0  |0         |\n",
      "|1  |1654733332|20.015       |56.67           |0       |400     |12345 |18651      |939.744     |0.0 |0.0  |0    |0.0  |0.0  |1  |0         |\n",
      "|2  |1654733333|20.029       |55.96           |0       |400     |12374 |18764      |939.738     |0.0 |0.0  |0    |0.0  |0.0  |2  |0         |\n",
      "|3  |1654733334|20.044       |55.28           |0       |400     |12390 |18849      |939.736     |0.0 |0.0  |0    |0.0  |0.0  |3  |0         |\n",
      "|4  |1654733335|20.059       |54.69           |0       |400     |12403 |18921      |939.744     |0.0 |0.0  |0    |0.0  |0.0  |4  |0         |\n",
      "|5  |1654733336|20.073       |54.12           |0       |400     |12419 |18998      |939.725     |0.0 |0.0  |0    |0.0  |0.0  |5  |0         |\n",
      "|6  |1654733337|20.088       |53.61           |0       |400     |12432 |19058      |939.738     |0.0 |0.0  |0    |0.0  |0.0  |6  |0         |\n",
      "|7  |1654733338|20.103       |53.2            |0       |400     |12439 |19114      |939.758     |0.0 |0.0  |0    |0.0  |0.0  |7  |0         |\n",
      "|8  |1654733339|20.117       |52.81           |0       |400     |12448 |19155      |939.758     |0.0 |0.0  |0    |0.0  |0.0  |8  |0         |\n",
      "|9  |1654733340|20.132       |52.46           |0       |400     |12453 |19195      |939.756     |0.9 |3.78 |0    |4.369|2.78 |9  |0         |\n",
      "|10 |1654733341|20.146       |52.15           |0       |400     |12454 |19230      |939.757     |0.89|3.71 |0    |4.289|2.73 |10 |0         |\n",
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3867a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+-----------------+\n",
      "|Fire_Alarm|Max_Temperature|Min_Temperature|     Avg_Humidity|\n",
      "+----------+---------------+---------------+-----------------+\n",
      "|         0|         20.146|           20.0|54.39181818181819|\n",
      "+----------+---------------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregated_df = new_df.groupBy(\"Fire_Alarm\").agg(\n",
    "    F.max(\"Temperature_C\").alias(\"Max_Temperature\"),\n",
    "    F.min(\"Temperature_C\").alias(\"Min_Temperature\"),\n",
    "    F.avg(\"Humidity_Percent\").alias(\"Avg_Humidity\"),\n",
    ")\n",
    "aggregated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "560a9732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|Temperature_C|count|\n",
      "+-------------+-----+\n",
      "|         20.0|    1|\n",
      "|       20.015|    1|\n",
      "|       20.029|    1|\n",
      "|       20.044|    1|\n",
      "|       20.059|    1|\n",
      "|       20.073|    1|\n",
      "|       20.088|    1|\n",
      "|       20.103|    1|\n",
      "|       20.117|    1|\n",
      "|       20.132|    1|\n",
      "|       20.146|    1|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.createOrReplaceTempView(\"sensor_data\")\n",
    "\n",
    "\n",
    "result_df = spark.sql(\"\"\"\n",
    "    SELECT `Temperature_C`, COUNT(*) as `count`\n",
    "    FROM sensor_data\n",
    "    GROUP BY `Temperature_C`\n",
    "    ORDER BY `Temperature_C`\n",
    "\"\"\")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c0cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-----------------+-----------------+\n",
      "|Fire_Alarm|0_Max_Temperature|0_Min_Temperature|   0_Avg_Humidity|\n",
      "+----------+-----------------+-----------------+-----------------+\n",
      "|         0|           20.146|             20.0|54.39181818181819|\n",
      "+----------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoting_df = new_df.groupBy(\"Fire_Alarm\") \\\n",
    "                    .pivot(\"Fire_Alarm\") \\\n",
    "                    .agg(F.max(\"Temperature_C\").alias(\"Max_Temperature\"),\n",
    "                         F.min(\"Temperature_C\").alias(\"Min_Temperature\"),\n",
    "                         F.avg(\"Humidity_Percent\").alias(\"Avg_Humidity\"))\n",
    "\n",
    "pivoting_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5ff9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+-----------------+\n",
      "|Fire_Alarm|Max_Temperature|Min_Temperature|     Avg_Humidity|\n",
      "+----------+---------------+---------------+-----------------+\n",
      "|      NULL|         20.146|           20.0|54.39181818181819|\n",
      "|         0|         20.146|           20.0|54.39181818181819|\n",
      "+----------+---------------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rollup_df = new_df.rollup(\"Fire_Alarm\") \\\n",
    "                  .agg(F.max(\"Temperature_C\").alias(\"Max_Temperature\"),\n",
    "                       F.min(\"Temperature_C\").alias(\"Min_Temperature\"),\n",
    "                       F.avg(\"Humidity_Percent\").alias(\"Avg_Humidity\"))\n",
    "rollup_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d43c132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+-----------------+\n",
      "|Fire_Alarm|Max_Temperature|Min_Temperature|     Avg_Humidity|\n",
      "+----------+---------------+---------------+-----------------+\n",
      "|      NULL|         20.146|           20.0|54.39181818181819|\n",
      "|         0|         20.146|           20.0|54.39181818181819|\n",
      "+----------+---------------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cubes_df = new_df.cube(\"Fire_Alarm\") \\\n",
    "                  .agg(F.max(\"Temperature_C\").alias(\"Max_Temperature\"),\n",
    "                       F.min(\"Temperature_C\").alias(\"Min_Temperature\"),\n",
    "                       F.avg(\"Humidity_Percent\").alias(\"Avg_Humidity\"))\n",
    "\n",
    "cubes_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97a4a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+----+\n",
      "|_c0|       UTC|Temperature_C|Humidity_Percent|TVOC_ppb|eCO2_ppm|Raw_H2|Raw_Ethanol|Pressure_hPa| PM1|PM2_5|NC0_5|NC1_5|NC2_5|CNT|Fire_Alarm|Rank|\n",
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+----+\n",
      "| 10|1654733341|       20.146|           52.15|       0|     400| 12454|      19230|     939.757|0.89| 3.71|    0|4.289| 2.73| 10|         0|   1|\n",
      "|  9|1654733340|       20.132|           52.46|       0|     400| 12453|      19195|     939.756| 0.9| 3.78|    0|4.369| 2.78|  9|         0|   2|\n",
      "|  8|1654733339|       20.117|           52.81|       0|     400| 12448|      19155|     939.758| 0.0|  0.0|    0|  0.0|  0.0|  8|         0|   3|\n",
      "|  7|1654733338|       20.103|            53.2|       0|     400| 12439|      19114|     939.758| 0.0|  0.0|    0|  0.0|  0.0|  7|         0|   4|\n",
      "|  6|1654733337|       20.088|           53.61|       0|     400| 12432|      19058|     939.738| 0.0|  0.0|    0|  0.0|  0.0|  6|         0|   5|\n",
      "|  5|1654733336|       20.073|           54.12|       0|     400| 12419|      18998|     939.725| 0.0|  0.0|    0|  0.0|  0.0|  5|         0|   6|\n",
      "|  4|1654733335|       20.059|           54.69|       0|     400| 12403|      18921|     939.744| 0.0|  0.0|    0|  0.0|  0.0|  4|         0|   7|\n",
      "|  3|1654733334|       20.044|           55.28|       0|     400| 12390|      18849|     939.736| 0.0|  0.0|    0|  0.0|  0.0|  3|         0|   8|\n",
      "|  2|1654733333|       20.029|           55.96|       0|     400| 12374|      18764|     939.738| 0.0|  0.0|    0|  0.0|  0.0|  2|         0|   9|\n",
      "|  1|1654733332|       20.015|           56.67|       0|     400| 12345|      18651|     939.744| 0.0|  0.0|    0|  0.0|  0.0|  1|         0|  10|\n",
      "|  0|1654733331|         20.0|           57.36|       0|     400| 12306|      18520|     939.735| 0.0|  0.0|    0|  0.0|  0.0|  0|         0|  11|\n",
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "windowSpec = Window.partitionBy(\"Fire_Alarm\").orderBy(F.desc(\"Temperature_C\"))\n",
    "\n",
    "ranking_df = new_df.withColumn(\"Rank\", F.rank().over(windowSpec))\n",
    "\n",
    "ranking_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2a579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+-------------------+\n",
      "|_c0|       UTC|Temperature_C|Humidity_Percent|TVOC_ppb|eCO2_ppm|Raw_H2|Raw_Ethanol|Pressure_hPa| PM1|PM2_5|NC0_5|NC1_5|NC2_5|CNT|Fire_Alarm|Cumulative_Humidity|\n",
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+-------------------+\n",
      "|  0|1654733331|         20.0|           57.36|       0|     400| 12306|      18520|     939.735| 0.0|  0.0|    0|  0.0|  0.0|  0|         0|              57.36|\n",
      "|  1|1654733332|       20.015|           56.67|       0|     400| 12345|      18651|     939.744| 0.0|  0.0|    0|  0.0|  0.0|  1|         0|             114.03|\n",
      "|  2|1654733333|       20.029|           55.96|       0|     400| 12374|      18764|     939.738| 0.0|  0.0|    0|  0.0|  0.0|  2|         0|             169.99|\n",
      "|  3|1654733334|       20.044|           55.28|       0|     400| 12390|      18849|     939.736| 0.0|  0.0|    0|  0.0|  0.0|  3|         0|             225.27|\n",
      "|  4|1654733335|       20.059|           54.69|       0|     400| 12403|      18921|     939.744| 0.0|  0.0|    0|  0.0|  0.0|  4|         0| 279.96000000000004|\n",
      "|  5|1654733336|       20.073|           54.12|       0|     400| 12419|      18998|     939.725| 0.0|  0.0|    0|  0.0|  0.0|  5|         0| 334.08000000000004|\n",
      "|  6|1654733337|       20.088|           53.61|       0|     400| 12432|      19058|     939.738| 0.0|  0.0|    0|  0.0|  0.0|  6|         0| 387.69000000000005|\n",
      "|  7|1654733338|       20.103|            53.2|       0|     400| 12439|      19114|     939.758| 0.0|  0.0|    0|  0.0|  0.0|  7|         0| 440.89000000000004|\n",
      "|  8|1654733339|       20.117|           52.81|       0|     400| 12448|      19155|     939.758| 0.0|  0.0|    0|  0.0|  0.0|  8|         0| 493.70000000000005|\n",
      "|  9|1654733340|       20.132|           52.46|       0|     400| 12453|      19195|     939.756| 0.9| 3.78|    0|4.369| 2.78|  9|         0|  546.1600000000001|\n",
      "| 10|1654733341|       20.146|           52.15|       0|     400| 12454|      19230|     939.757|0.89| 3.71|    0|4.289| 2.73| 10|         0|  598.3100000000001|\n",
      "+---+----------+-------------+----------------+--------+--------+------+-----------+------------+----+-----+-----+-----+-----+---+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"Fire_Alarm\").orderBy(\"UTC\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "analytic_df = new_df.withColumn(\"Cumulative_Humidity\", F.sum(\"Humidity_Percent\").over(windowSpec))\n",
    "\n",
    "analytic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2eeeb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c515c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers='localhost:9092',\n",
    "                         value_serializer=lambda v: json.dumps(v).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19a9510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_topic = 'output'\n",
    "def sendKafka(df):\n",
    "    print(\"STarting to send the data to kafka\")\n",
    "    count = 0\n",
    "    for row in df.collect():\n",
    "        producer.send(kafka_topic, row.asDict())\n",
    "        producer.flush()\n",
    "        if count == 10:\n",
    "            break\n",
    "        count += 1\n",
    "    print(\"data sent!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad79badc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STarting to send the data to kafka\n",
      "data sent!\n"
     ]
    }
   ],
   "source": [
    "sendKafka(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2f14ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STarting to send the data to kafka\n",
      "data sent!\n"
     ]
    }
   ],
   "source": [
    "sendKafka(pivoting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d937f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STarting to send the data to kafka\n",
      "data sent!\n"
     ]
    }
   ],
   "source": [
    "sendKafka(rollup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "447292d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STarting to send the data to kafka\n",
      "data sent!\n"
     ]
    }
   ],
   "source": [
    "sendKafka(cubes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a2ed8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STarting to send the data to kafka\n",
      "data sent!\n"
     ]
    }
   ],
   "source": [
    "sendKafka(ranking_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fece9195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STarting to send the data to kafka\n",
      "data sent!\n"
     ]
    }
   ],
   "source": [
    "sendKafka(analytic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71a96462",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7bcbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95481e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
